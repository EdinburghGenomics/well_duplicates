#!/bin/bash
# vim: ft=python

# Execution script for count_well_duplicates.py based on Snakemake
# Requires Snakemake in your default PATH, and the well_duplicates
# Python scripts to be in the same dir as this script or in your
# default PATH (remember temporary settings of $PATH don't transfer
# over the cluster).
# If $DATADIR is set, reads from that folder, else CWD
# If $WORKDIR is set, works in that folder, else
# ../../runqc/WellDuplicates/`basename $PWD`

# Contents >>>
#   + Embedded BASH script to bootstrap the workflow
#   + Initialisation and configuration
#   + Helper functions
#   + The rules specific to this workflow
#   + More generic rules

"""true" ### Begin shell script part
set -e ; set -u ; set -x

threads=${SNAKE_THREADS:-8}

datadir="${DATADIR:-`pwd`}"
test -e "$datadir"

#Don't run until there is a RTARead1Complete.txt touch file,
#and a RunInfo.xml
test -e "$datadir"/RTARead1Complete.txt
test -e "$datadir"/Data/Intensities/s.locs
test -e "$datadir"/RunInfo.xml

workdir="${WORKDIR:-$DATADIR/../../runqc/WellDuplicates/`basename $DATADIR`}"
#Make $workdir and in the process ensure the script only runs once.
#Link the $datadir back to the $workdir
mkdir "$workdir"
ln -sr "$datadir" "$workdir/datadir"

#Before changing dir, get the real path to this file on the assumption that
#count_well_duplicates.py may well be there.
#I can't just prepend it to the PATH as it won't carry across to cluster jobs.
scriptdir="`dirname $0`"

## And off we go.
if [ "${NOCLUSTER:-0}" = 1 ] ; then
    set +e
    snakemake -s "$0" -j 1 --config workdir="$workdir" -- "$@"
else
    ## Ensure the cluster output is going to the right place.
    mkdir -p "$workdir"/sge_output

    set +e
    snakemake \
     -s "$0" -j $threads -T \
     --config workdir="$workdir" scriptdir="$scriptdir" \
     -p --jobname "{rulename}.snakejob.{jobid}.sh" \
     --drmaa " -q qc -cwd -S /bin/bash -p -10 -V -pe single \
               -o "$workdir"/sge_output -e "$workdir"/sge_output \
             " \
     -- "$@"
fi

"exit""" ### End of shell script part

#!/usr/bin/env snakemake
from snakemake.utils import format

#Regular glob() is useful but it can be improved like so.
import os
from glob import glob as _glob
glob = lambda pathname: sorted(_glob(os.path.expanduser(pathname)))

workdir: config['workdir']

#Configuration options
targets_to_sample = 10000
lanes_to_sample = "1 2 3 4 5 6 7 8"
levels_to_scan = 5
report_verbose = True

#Find the scripts if they are in the same folder as this one,
#even if it's not in the default PATH.
if 'scriptdir' in config:
    _PATHSET = 'PATH=\'%s\'":$PATH" ' % config['scriptdir']
else
    _PATHSET = ''

PREP_INDICES    =_PATHSET + "prepare_cluster_indexes.py"
COUNT_WELL_DUPL =_PATHSET + "count_well_duplicates.py"

### Helper functions

"""This is somewhat backwards.  The scripts only use the machine type
   to decide how many tiles to process, but here we look at the number
   of tiles in order to infer the machine type.
"""
if shell("grep -q '<Tile>._2228</Tile>' datadir/RunInfo.xml"):
    MACHTYPE = 'hiseq_4000'
else:
    MACHTYPE = 'hiseq_x'

### Specific rules
localrules: main

"""Main rule just defines everything to be generated.
   For simplicity, I'm storing all the results directly in the
   sequence data folder.
"""
rule main:
    input: expand( "dupes_{targets}_{lane}.txt",
                   targets=int(targets_to_sample),
                   lane=lanes_to_sample.split() )

rule count_well_dupl:
    output: "dupes_{targets}_{lane}.txt"
    input: targets=MACHTYPE + "_{targets}clusters.list"
    params: startpos=20, endpos=70, levels=5
    shell:
        "{COUNT_WELL_DUPL} -f {input.targets} -s {MACHTYPE} -r datadir" +
        " -i {wildcards.lane} -l {params.levels} -x {params.startpos} -y {params.endpos}" +
        " > {output}"

rule prep_indices:
    output: MACHTYPE + "_{targets}clusters.list"
    shell:
        "{PREP_INDICES} -n {targets} -f datadir/Data/Intensities/s.locs > {output}"


### Generic rules

# none
